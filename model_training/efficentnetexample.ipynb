{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Xz6yWIRVx6IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width=224\n",
        "img_height=224\n",
        "batch_size=32\n",
        "num_of_classes=17\n",
        "IMG_SIZE=224\n",
        "\n",
        "\n",
        "training_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/train\"\n",
        "validation_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/val\"\n",
        "test_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/test\"\n",
        "all_data_directory = \"/content/drive/MyDrive/Datasets/gemstone2/all\""
      ],
      "metadata": {
        "id": "CnFrSX3VTcbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ImageDataGenerator( ##rescale = 1./255,\n",
        "                                   horizontal_flip=True,\n",
        "                                    vertical_flip = True,\n",
        "                                   #validation_split=0.2\n",
        "                                   )\n",
        "\n",
        "validation_data = ImageDataGenerator ( ##rescale = 1./255,\n",
        "                                      horizontal_flip=True,\n",
        "                                      vertical_flip = True,\n",
        "                                    )\n",
        "\n",
        "test_data = ImageDataGenerator ( ##rescale = 1./255,\n",
        "                                      horizontal_flip=True,\n",
        "                                      vertical_flip = True,\n",
        "                                    )\n"
      ],
      "metadata": {
        "id": "4zHt1YkVVgqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_gen = train_data.flow_from_directory(training_set_directory,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle = True,\n",
        "                                                 target_size = (img_height, img_width),\n",
        "                                           # subset='training')\n",
        ")\n",
        "\n",
        "validation_gen = validation_data.flow_from_directory(validation_set_directory,\n",
        "                                                     batch_size = batch_size,\n",
        "                                                     class_mode = 'categorical',\n",
        "                                                     shuffle = True,\n",
        "                                                     target_size = (img_height, img_width),\n",
        "                                                     #subset='validation')\n",
        ")\n",
        "\n",
        "test_gen = test_data.flow_from_directory(test_set_directory,\n",
        "                                                     batch_size = batch_size,\n",
        "                                                     class_mode = 'categorical',\n",
        "                                                     shuffle = True,\n",
        "                                                     target_size = (img_height, img_width),\n",
        "                                                     #subset='validation')\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2AjBeecVnBt",
        "outputId": "880f513f-2dda-4a43-e504-1f460c7bbdc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6542 images belonging to 70 classes.\n",
            "Found 1857 images belonging to 70 classes.\n",
            "Found 1000 images belonging to 70 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        layers.RandomRotation(factor=0.1),\n",
        "        #layers.RandomTranslation(height_factor=0.25, width_factor=0.25),\n",
        "        layers.RandomFlip(),\n",
        "        layers.RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\",\n",
        ")"
      ],
      "metadata": {
        "id": "mr0jI2UDVsfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ntB6ydYu0vk"
      },
      "outputs": [],
      "source": [
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    x = img_augmentation(inputs)\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = model.output\n",
        "    x = layers.Conv2D(5120, kernel_size=2, activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    outputs = layers.Dense(70, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(num_classes=70)\n",
        "\n",
        "epochs = 100\n",
        "\n"
      ],
      "metadata": {
        "id": "mnoiVuBdbP7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "9JwB_vmOnzq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(training_gen, epochs=epochs, validation_data=validation_gen, verbose=1, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti30IkmAe0mR",
        "outputId": "4770d589-301c-4a80-e69e-efac0bf97fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "205/205 [==============================] - 89s 220ms/step - loss: 2.3336 - accuracy: 0.4499 - val_loss: 2.0067 - val_accuracy: 0.5401\n",
            "Epoch 2/100\n",
            "205/205 [==============================] - 44s 212ms/step - loss: 1.2821 - accuracy: 0.6376 - val_loss: 1.4757 - val_accuracy: 0.6193\n",
            "Epoch 3/100\n",
            "205/205 [==============================] - 41s 198ms/step - loss: 0.9862 - accuracy: 0.7051 - val_loss: 1.4267 - val_accuracy: 0.6381\n",
            "Epoch 4/100\n",
            "205/205 [==============================] - 43s 210ms/step - loss: 0.8462 - accuracy: 0.7437 - val_loss: 1.5254 - val_accuracy: 0.6462\n",
            "Epoch 5/100\n",
            "205/205 [==============================] - 41s 200ms/step - loss: 0.7456 - accuracy: 0.7686 - val_loss: 1.3629 - val_accuracy: 0.6742\n",
            "Epoch 6/100\n",
            "205/205 [==============================] - 41s 200ms/step - loss: 0.6920 - accuracy: 0.7884 - val_loss: 1.3017 - val_accuracy: 0.6791\n",
            "Epoch 7/100\n",
            "205/205 [==============================] - 40s 192ms/step - loss: 0.6307 - accuracy: 0.8057 - val_loss: 1.4448 - val_accuracy: 0.6656\n",
            "Epoch 8/100\n",
            "205/205 [==============================] - 41s 200ms/step - loss: 0.5758 - accuracy: 0.8205 - val_loss: 1.4891 - val_accuracy: 0.6801\n",
            "Epoch 9/100\n",
            "205/205 [==============================] - 42s 202ms/step - loss: 0.5037 - accuracy: 0.8390 - val_loss: 1.3325 - val_accuracy: 0.7060\n",
            "Epoch 10/100\n",
            "205/205 [==============================] - 40s 193ms/step - loss: 0.4930 - accuracy: 0.8488 - val_loss: 1.4075 - val_accuracy: 0.7044\n",
            "Epoch 11/100\n",
            "205/205 [==============================] - 39s 191ms/step - loss: 0.4807 - accuracy: 0.8473 - val_loss: 1.5185 - val_accuracy: 0.6850\n",
            "Epoch 12/100\n",
            "205/205 [==============================] - 41s 200ms/step - loss: 0.4388 - accuracy: 0.8652 - val_loss: 1.4327 - val_accuracy: 0.7108\n",
            "Epoch 13/100\n",
            "205/205 [==============================] - 41s 199ms/step - loss: 0.4010 - accuracy: 0.8739 - val_loss: 1.3980 - val_accuracy: 0.7194\n",
            "Epoch 14/100\n",
            "205/205 [==============================] - 39s 192ms/step - loss: 0.3775 - accuracy: 0.8823 - val_loss: 1.4931 - val_accuracy: 0.7022\n",
            "Epoch 15/100\n",
            "205/205 [==============================] - 40s 194ms/step - loss: 0.4255 - accuracy: 0.8704 - val_loss: 1.4831 - val_accuracy: 0.7071\n",
            "Epoch 16/100\n",
            "205/205 [==============================] - 39s 192ms/step - loss: 0.3431 - accuracy: 0.8913 - val_loss: 1.5554 - val_accuracy: 0.7097\n",
            "Epoch 17/100\n",
            "205/205 [==============================] - 41s 199ms/step - loss: 0.3444 - accuracy: 0.8990 - val_loss: 1.4876 - val_accuracy: 0.7205\n",
            "Epoch 18/100\n",
            "205/205 [==============================] - 39s 191ms/step - loss: 0.3408 - accuracy: 0.8954 - val_loss: 1.5796 - val_accuracy: 0.7044\n",
            "Epoch 19/100\n",
            "205/205 [==============================] - 41s 202ms/step - loss: 0.3507 - accuracy: 0.8890 - val_loss: 1.5500 - val_accuracy: 0.7237\n",
            "Epoch 20/100\n",
            "205/205 [==============================] - 39s 191ms/step - loss: 0.3381 - accuracy: 0.8993 - val_loss: 1.5698 - val_accuracy: 0.7167\n",
            "Epoch 21/100\n",
            "205/205 [==============================] - 41s 201ms/step - loss: 0.3080 - accuracy: 0.9097 - val_loss: 1.4967 - val_accuracy: 0.7313\n",
            "Epoch 22/100\n",
            "205/205 [==============================] - 40s 193ms/step - loss: 0.2943 - accuracy: 0.9094 - val_loss: 1.4621 - val_accuracy: 0.7281\n",
            "Epoch 23/100\n",
            "205/205 [==============================] - 42s 204ms/step - loss: 0.2778 - accuracy: 0.9094 - val_loss: 1.6562 - val_accuracy: 0.7200\n",
            "Epoch 24/100\n",
            "205/205 [==============================] - 40s 193ms/step - loss: 0.2744 - accuracy: 0.9193 - val_loss: 1.5972 - val_accuracy: 0.7221\n",
            "Epoch 25/100\n",
            "205/205 [==============================] - 40s 195ms/step - loss: 0.2658 - accuracy: 0.9149 - val_loss: 1.6140 - val_accuracy: 0.7254\n",
            "Epoch 26/100\n",
            "205/205 [==============================] - 43s 208ms/step - loss: 0.2945 - accuracy: 0.9144 - val_loss: 1.5033 - val_accuracy: 0.7254\n",
            "Epoch 27/100\n",
            "205/205 [==============================] - 41s 201ms/step - loss: 0.2632 - accuracy: 0.9179 - val_loss: 1.4961 - val_accuracy: 0.7421\n",
            "Epoch 28/100\n",
            "205/205 [==============================] - 39s 189ms/step - loss: 0.2305 - accuracy: 0.9288 - val_loss: 1.5684 - val_accuracy: 0.7291\n",
            "Epoch 29/100\n",
            "122/205 [================>.............] - ETA: 12s - loss: 0.2274 - accuracy: 0.9313"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath2 = '/tmp/checkpoint2'\n",
        "model_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath2,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "IMphHohDoGzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "model.load_weights(checkpoint_filepath)\n",
        "\n",
        "unfreeze_model(model)\n",
        "\n",
        "epochs = 100\n",
        "hist = model.fit(training_gen, epochs=epochs, validation_data=validation_gen, verbose=1, callbacks=[model_checkpoint_callback2])\n"
      ],
      "metadata": {
        "id": "q4n6nWx3cCk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_filepath2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr80YoPFBXLy",
        "outputId": "62c9ab4d-7593-44f5-e7c9-374d68772c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4d203f56c0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKCsDdoyDADz",
        "outputId": "20359402-540d-4b56-e41c-d128ea02f5ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 1s 57ms/step - loss: 0.9869 - accuracy: 0.8041\n"
          ]
        }
      ]
    }
  ]
}