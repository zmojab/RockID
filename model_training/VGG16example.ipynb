{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmQkxmPBtzUQ"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXpv0Qjbt87i",
        "outputId": "81d811ad-e82d-4194-f0d8-fb92b6179c20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6542 images belonging to 70 classes.\n",
            "Found 1857 images belonging to 70 classes.\n",
            "Found 1000 images belonging to 70 classes.\n"
          ]
        }
      ],
      "source": [
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 128\n",
        "num_of_classes = 70\n",
        "IMG_SIZE = 224\n",
        "\n",
        "training_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/train\"\n",
        "validation_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/val\"\n",
        "test_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/test\"\n",
        "\n",
        "train_data = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "validation_data = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_data = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "training_gen = train_data.flow_from_directory(\n",
        "    training_set_directory,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width)\n",
        ")\n",
        "\n",
        "validation_gen = validation_data.flow_from_directory(\n",
        "    validation_set_directory,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width)\n",
        ")\n",
        "\n",
        "test_gen = test_data.flow_from_directory(\n",
        "    test_set_directory,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBbyHqUxuFrp"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "checkpoint_filepath = '/tmp/checkpoint'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4TBvqDSsyNC",
        "outputId": "b5492a98-7da4-4a51-a905-5c206301958c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "52/52 [==============================] - 1658s 32s/step - loss: 8.1785 - accuracy: 0.0297 - val_loss: 3.9834 - val_accuracy: 0.0878\n",
            "Epoch 2/10\n",
            "52/52 [==============================] - 120s 2s/step - loss: 4.0620 - accuracy: 0.0556 - val_loss: 3.7725 - val_accuracy: 0.1002\n",
            "Epoch 3/10\n",
            "52/52 [==============================] - 118s 2s/step - loss: 3.9309 - accuracy: 0.0738 - val_loss: 3.6144 - val_accuracy: 0.1206\n",
            "Epoch 4/10\n",
            "52/52 [==============================] - 116s 2s/step - loss: 3.8375 - accuracy: 0.0786 - val_loss: 3.4571 - val_accuracy: 0.1325\n",
            "Epoch 5/10\n",
            "52/52 [==============================] - 127s 2s/step - loss: 3.7535 - accuracy: 0.0815 - val_loss: 3.3841 - val_accuracy: 0.1206\n",
            "Epoch 6/10\n",
            "52/52 [==============================] - 120s 2s/step - loss: 3.7084 - accuracy: 0.0809 - val_loss: 3.4473 - val_accuracy: 0.1131\n",
            "Epoch 7/10\n",
            "52/52 [==============================] - 119s 2s/step - loss: 3.6845 - accuracy: 0.0824 - val_loss: 3.3039 - val_accuracy: 0.1228\n",
            "Epoch 8/10\n",
            "52/52 [==============================] - 119s 2s/step - loss: 3.7671 - accuracy: 0.0781 - val_loss: 3.3579 - val_accuracy: 0.1061\n",
            "Epoch 9/10\n",
            "52/52 [==============================] - 118s 2s/step - loss: 3.7603 - accuracy: 0.0714 - val_loss: 3.3130 - val_accuracy: 0.1115\n",
            "Epoch 10/10\n",
            "52/52 [==============================] - 118s 2s/step - loss: 3.7190 - accuracy: 0.0741 - val_loss: 3.2461 - val_accuracy: 0.1190\n"
          ]
        }
      ],
      "source": [
        "\n",
        "epochs = 100\n",
        "\n",
        "hist = model.fit(\n",
        "    training_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_gen,\n",
        "    verbose=1,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}