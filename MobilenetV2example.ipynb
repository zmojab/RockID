{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4avxHvUurvPM"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, GlobalMaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkIx4ShQrwP_",
        "outputId": "a1b41b32-7d65-492d-e518-74c589c31e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6542 images belonging to 70 classes.\n",
            "Found 1857 images belonging to 70 classes.\n",
            "Found 1000 images belonging to 70 classes.\n"
          ]
        }
      ],
      "source": [
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 256\n",
        "num_of_classes = 70\n",
        "IMG_SIZE = 224\n",
        "\n",
        "training_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/train\"\n",
        "validation_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/val\"\n",
        "test_set_directory = \"/content/drive/MyDrive/Datasets/polishedGemstones/test\"\n",
        "\n",
        "train_data = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "validation_data = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_data = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "training_gen = train_data.flow_from_directory(\n",
        "    training_set_directory,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width)\n",
        ")\n",
        "\n",
        "validation_gen = validation_data.flow_from_directory(\n",
        "    validation_set_directory,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width)\n",
        ")\n",
        "\n",
        "test_gen = test_data.flow_from_directory(\n",
        "    test_set_directory,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    target_size=(img_height, img_width)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-5f8CN3rwnK",
        "outputId": "ac94104d-08d6-42a8-d798-f5e5161a24d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "x = Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.6)(x)\n",
        "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "\n",
        "for layer in model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "optimizer = Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tF3YpzuErwpx"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = '/tmp/checkpoint2'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCa9tOUguhXp"
      },
      "outputs": [],
      "source": [
        "total_training_samples = len(training_gen.filenames)\n",
        "steps_per_epoch = total_training_samples // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHdIWKB7rwsH",
        "outputId": "efcbfd0f-aecb-4698-84e8-f5ffbec331a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            " 7/25 [=======>......................] - ETA: 1:00:33 - loss: 29.7491 - accuracy: 0.0179"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    training_gen,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=validation_gen,\n",
        "    verbose=1,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY1esJajrsoh",
        "outputId": "e5bac3e8-ce9a-402f-8f45-0926a7d127a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x78490f26ded0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "model.load_weights(checkpoint_filepath)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQEEwt9lktx1"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.save('/tmp/goodcheckpoint.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpVFGjNukwmB",
        "outputId": "578bd52d-b5e7-459e-b2e6-3013af350a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 4s 925ms/step - loss: 3.1415 - accuracy: 0.7220\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[3.1414966583251953, 0.722000002861023]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_gen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP9-MOtVS-Gr"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmctYyWCHOtz",
        "outputId": "4094b138-8876-4b01-c61b-43e9cea52282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 84s 3s/step - loss: 2.8946 - accuracy: 0.8271 - val_loss: 3.2146 - val_accuracy: 0.7518\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 83s 3s/step - loss: 2.8663 - accuracy: 0.8331 - val_loss: 3.2062 - val_accuracy: 0.7458\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.8684 - accuracy: 0.8263 - val_loss: 3.1984 - val_accuracy: 0.7485\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 83s 3s/step - loss: 2.8518 - accuracy: 0.8303 - val_loss: 3.1927 - val_accuracy: 0.7550\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 83s 3s/step - loss: 2.8445 - accuracy: 0.8333 - val_loss: 3.1845 - val_accuracy: 0.7561\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 83s 3s/step - loss: 2.8188 - accuracy: 0.8392 - val_loss: 3.1778 - val_accuracy: 0.7518\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 83s 3s/step - loss: 2.8378 - accuracy: 0.8288 - val_loss: 3.1684 - val_accuracy: 0.7523\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.8173 - accuracy: 0.8395 - val_loss: 3.1636 - val_accuracy: 0.7496\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 83s 3s/step - loss: 2.8003 - accuracy: 0.8398 - val_loss: 3.1564 - val_accuracy: 0.7518\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 83s 3s/step - loss: 2.8138 - accuracy: 0.8320 - val_loss: 3.1470 - val_accuracy: 0.7523\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.8079 - accuracy: 0.8311 - val_loss: 3.1395 - val_accuracy: 0.7507\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 85s 3s/step - loss: 2.7859 - accuracy: 0.8371 - val_loss: 3.1345 - val_accuracy: 0.7501\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7801 - accuracy: 0.8376 - val_loss: 3.1271 - val_accuracy: 0.7539\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7738 - accuracy: 0.8390 - val_loss: 3.1225 - val_accuracy: 0.7561\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7627 - accuracy: 0.8385 - val_loss: 3.1154 - val_accuracy: 0.7507\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7404 - accuracy: 0.8513 - val_loss: 3.1075 - val_accuracy: 0.7539\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7447 - accuracy: 0.8425 - val_loss: 3.0997 - val_accuracy: 0.7561\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7349 - accuracy: 0.8446 - val_loss: 3.0929 - val_accuracy: 0.7561\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7441 - accuracy: 0.8309 - val_loss: 3.0869 - val_accuracy: 0.7577\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 82s 3s/step - loss: 2.7252 - accuracy: 0.8428 - val_loss: 3.0801 - val_accuracy: 0.7555\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    training_gen,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=validation_gen,\n",
        "    verbose=1,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al3Cl2jDlSFQ"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers[-15:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RFOp5yYl3VY",
        "outputId": "b397259e-9ab3-4672-99ee-5d33964c2e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 101/110\n",
            "26/26 [==============================] - 97s 3s/step - loss: 1.5944 - accuracy: 0.7661 - val_loss: 1.9372 - val_accuracy: 0.7065\n",
            "Epoch 102/110\n",
            "26/26 [==============================] - 91s 4s/step - loss: 1.3484 - accuracy: 0.8341 - val_loss: 1.8749 - val_accuracy: 0.7286\n",
            "Epoch 103/110\n",
            "26/26 [==============================] - 90s 4s/step - loss: 1.2635 - accuracy: 0.8510 - val_loss: 1.8572 - val_accuracy: 0.7297\n",
            "Epoch 104/110\n",
            "26/26 [==============================] - 90s 3s/step - loss: 1.1936 - accuracy: 0.8751 - val_loss: 1.8447 - val_accuracy: 0.7356\n",
            "Epoch 105/110\n",
            "26/26 [==============================] - 90s 3s/step - loss: 1.1573 - accuracy: 0.8786 - val_loss: 1.8232 - val_accuracy: 0.7367\n",
            "Epoch 106/110\n",
            "26/26 [==============================] - 93s 4s/step - loss: 1.1213 - accuracy: 0.8912 - val_loss: 1.8871 - val_accuracy: 0.7189\n",
            "Epoch 107/110\n",
            "26/26 [==============================] - 91s 4s/step - loss: 1.1140 - accuracy: 0.8893 - val_loss: 1.8124 - val_accuracy: 0.7410\n",
            "Epoch 108/110\n",
            "26/26 [==============================] - 91s 4s/step - loss: 1.0839 - accuracy: 0.8971 - val_loss: 1.9034 - val_accuracy: 0.7151\n",
            "Epoch 109/110\n",
            "26/26 [==============================] - 91s 3s/step - loss: 1.0607 - accuracy: 0.9074 - val_loss: 1.8448 - val_accuracy: 0.7367\n",
            "Epoch 110/110\n",
            "26/26 [==============================] - 91s 4s/step - loss: 1.0351 - accuracy: 0.9080 - val_loss: 1.8540 - val_accuracy: 0.7248\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "history = model.fit(\n",
        "    training_gen,\n",
        "    epochs=epochs + fine_tune_epochs,\n",
        "    initial_epoch=epochs,\n",
        "    validation_data=validation_gen,\n",
        "    verbose=1,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}